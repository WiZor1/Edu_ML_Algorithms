{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сформировать с помощью `sklearn.make_classification` датасет из 1000 объектов с двумя признаками, обучить случайный лес из 1, 3, 10 и 50, 100, 200 деревьев и визуализировать их разделяющие гиперплоскости на графиках (по подобию визуализации деревьев из предыдущего урока, необходимо только заменить вызов функции `predict` на `tree_vote`). Сделать выводы о получаемой сложности гиперплоскости и недообучении или переобучении случайного леса в зависимости от количества деревьев в нем.\n",
    "2. (опция). Заменить в реализованном алгоритме проверку с помощью отложенной выборки на Out-of-Bag.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся наработками прошлого занятия и заимствуем реализацию дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    Узел решающего дерева, храняющий определитель признака и порогового значения, а также\n",
    "    направления на следующие узлы.\n",
    "    '''\n",
    "    def __init__(self, index, thershold, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака\n",
    "        self.thershold = thershold\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    '''\n",
    "    Узлы, в которых происходит выдача предсказания и дальше дерево не строится\n",
    "    '''\n",
    "    def __init__(self, data, labels, prediction_type):\n",
    "        self.data = np.array(data)\n",
    "        self.labels = np.array(labels)\n",
    "        self.prediction_type = prediction_type\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        if self.prediction_type == 'classification':\n",
    "            classes, labels_cnt = np.unique(self.labels, return_counts=True)\n",
    "            prediction = classes[labels_cnt == labels_cnt.max()][0]\n",
    "        elif self.prediction_type == 'regression':\n",
    "            prediction = self.labels.mean()\n",
    "        return prediction\n",
    "\n",
    "class DecisionTree:\n",
    "    '''\n",
    "    Классификатор или регрессор, построенный на алгоритме решающего дерева.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predict_type: str {\"classification\", \"regression\"}\n",
    "        Тип решаемой задачи алгоритмом. По умолчанию \"classification\"\n",
    "    max_depth: int\n",
    "        Максимальная глубина дерева.\n",
    "    min_leaf: int\n",
    "        Минимальное число объектов на одном листе дерева.\n",
    "    criterion: {\"gini\", \"entropy\"}\n",
    "        Критерий разбиения значения в разные узлы для классификации.\n",
    "        Для задачи регрессии используется оценка дисперсии признаков и атрибут не учитывается.\n",
    "    max_leafes_number: int\n",
    "        Максимальное число листьев. В текущей реализации возможны случаи,\n",
    "        когда количество листьев будет несколько выше указанного значения.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 predict_type: str='classification',\n",
    "                 max_depth: int=None,\n",
    "                 min_leaf: int=1,\n",
    "                 criterion: str='gini',\n",
    "                 max_leafes_number: int=None):\n",
    "        # перечисленные параметры являются параметрами останова, настраиваемыми далее. 1 задание\n",
    "        self.__predict_type = predict_type\n",
    "        self.__max_depth = max_depth\n",
    "        self.__min_leaf = min_leaf\n",
    "        if predict_type == 'regression':\n",
    "            criterion = 'variance'\n",
    "        self.__criterion = criterion\n",
    "        self.__max_leafes_number = max_leafes_number\n",
    "        self.__n_leafs = 0\n",
    "    \n",
    "    def _gini(self, labels: np.array):\n",
    "        '''\n",
    "        Расчет порогового значения в узле(Node) на основании критерия Джини.\n",
    "        Первая часть 2 задания\n",
    "        '''        \n",
    "        labels = np.array(labels)\n",
    "        classes, size = np.unique(labels, return_counts=True)\n",
    "        impurity = 1 - ((size / labels.shape)**2).sum()\n",
    "        return impurity\n",
    "        \n",
    "    def _entropy(self, labels: np.array):\n",
    "        '''\n",
    "        Расчет порогового значения в узле(Node) на основании энтропии.\n",
    "        Первая часть 2 задания\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        classes, size = np.unique(labels, return_counts=True)\n",
    "        p = size / labels.shape\n",
    "        impurity = - (p * np.log2(p)).sum()\n",
    "        return impurity\n",
    "\n",
    "    def _variance(self, labels: np.array):\n",
    "        '''\n",
    "        Расчет порогового значения в узле(Node) на основании дисперсии целевой переменной.\n",
    "        3 задание\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        M_x = labels.mean()\n",
    "        impurity = ((labels - M_x)**2).mean()\n",
    "        return impurity\n",
    "    \n",
    "    def _quality(self, left_labels, right_labels, criteria_current):\n",
    "        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "        if self.__criterion == 'gini':\n",
    "            criteria = self._gini\n",
    "        elif self.__criterion == 'entropy':\n",
    "            criteria = self._entropy\n",
    "        elif self.__criterion == 'variance':\n",
    "            criteria = self._variance\n",
    "        return criteria_current - p * criteria(left_labels) - (1 - p) * criteria(right_labels)\n",
    "    \n",
    "    def _split(self, data, labels, index, t):\n",
    "        left = np.where(data[:, index] <= t)\n",
    "        right = np.where(data[:, index] > t)\n",
    "\n",
    "        true_data = data[left]\n",
    "        false_data = data[right]\n",
    "        true_labels = labels[left]\n",
    "        false_labels = labels[right]\n",
    "\n",
    "        return true_data, false_data, true_labels, false_labels\n",
    "    \n",
    "    def _find_best_split(self, data, labels):\n",
    "        if self.__criterion == 'gini':\n",
    "            criteria = self._gini\n",
    "        elif self.__criterion == 'entropy':\n",
    "            criteria = self._entropy\n",
    "        elif self.__criterion == 'variance':\n",
    "            criteria = self._variance\n",
    "            \n",
    "        criteria_current = criteria(labels)\n",
    "\n",
    "        best_quality = 0\n",
    "        best_t = None\n",
    "        best_index = None\n",
    "\n",
    "        n_features = data.shape[1]\n",
    "\n",
    "        for index in range(n_features):\n",
    "            t_values = np.unique(data[:, index])\n",
    "\n",
    "            for t in t_values:\n",
    "                true_data, false_data, true_labels, false_labels = self._split(data, labels, index, t)\n",
    "                if min(len(true_data), len(false_data)) < self.__min_leaf:\n",
    "                    continue\n",
    "\n",
    "                current_quality = self._quality(true_labels, false_labels, criteria_current)\n",
    "\n",
    "                if current_quality > best_quality:\n",
    "                    best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "        return best_quality, best_t, best_index\n",
    "    \n",
    "    def _build_tree(self, data, labels, depth=0):\n",
    "        quality, t, index = self._find_best_split(data, labels)\n",
    "\n",
    "        if quality == 0 or (self.__max_depth is not None and depth >= self.__max_depth)\\\n",
    "        or (self.__max_leafes_number is not None and self.__n_leafs >= self.__max_leafes_number - 1):\n",
    "            self.__n_leafs += 1\n",
    "            return Leaf(data, labels, self.__predict_type)\n",
    "\n",
    "        true_data, false_data, true_labels, false_labels = self._split(data, labels, index, t)\n",
    "        \n",
    "        true_branch = self._build_tree(true_data, true_labels, depth + 1)\n",
    "        false_branch = self._build_tree(false_data, false_labels, depth + 1)\n",
    "\n",
    "        return Node(index, t, true_branch, false_branch)\n",
    "    \n",
    "    def _classify_object(self, obj, node):\n",
    "        if isinstance(node, Leaf):\n",
    "            answer = node.prediction\n",
    "            return answer\n",
    "\n",
    "        if obj[node.index] <= node.thershold:\n",
    "            return self._classify_object(obj, node.true_branch)\n",
    "        else:\n",
    "            return self._classify_object(obj, node.false_branch)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучает модель.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X, y: array like\n",
    "            Значения признаков и целевой переменной\n",
    "        '''\n",
    "        self.__tree = self._build_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Отдает предсказания обученной модели.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: array like\n",
    "            Значения признаков\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "#         classes = []\n",
    "#         for obj in X:\n",
    "#             prediction = self._classify_object(obj, self.__tree)\n",
    "#             classes.append(prediction)\n",
    "#         return classes\n",
    "        classes = np.array([])\n",
    "        for obj in X:\n",
    "            prediction = self._classify_object(obj, self.__tree)\n",
    "            classes = np.append(classes, prediction)\n",
    "        return classes\n",
    "    \n",
    "    def fit_predict(self, X, y):\n",
    "        '''\n",
    "        Обучает модель и отдает ее предсказания.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X, y: array like\n",
    "            Значения признаков и целевой переменной\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "        self.fit(X, y)\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrapAggregation():\n",
    "    '''\n",
    "    Алгоритм, основанный на усреднении предсказаний ряда базовых алгоритмов.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    algorithm: type\n",
    "        Тип базового алгоритма, участвующего в bootstrap агрегации.\n",
    "        Гиперпараметры передаются сразу после указания всех параметров для BootstrapAggregation.\n",
    "            ВАЖНО: передавать следует сам тип, а не экземпляр алгоритма: например,\n",
    "            DecisionTreeClassifier вместо DecisionTreeClassifier().\n",
    "    alg_count: int\n",
    "        Количество базовых алгоритмов, участвующих в обучении.\n",
    "    sample_size: int\n",
    "        Размер перемешанной выборки с возвращением, участвующей в обучении.\n",
    "    features_in_sample: int\n",
    "        Количество признаков, участвующие в обучении.\n",
    "    OOB: bool\n",
    "        Метка, указывающая, следует ли активировать механизм Out-of-Bag.\n",
    "        При нем выборка, не участвовавшая в процессе обучения используется для предсказания результатов,\n",
    "        тем самым убирая необходимость использования кросс-валидации.\n",
    "    '''\n",
    "    def __init__(self, algorithm, alg_count=50, sample_size=None, features_in_sample=None, OOB=False, **kwargs):\n",
    "        if isinstance(algorithm, type):\n",
    "            self.__algorithm = algorithm\n",
    "        else:\n",
    "            raise TypeError('В \"algorithm\" принимается тип алгоритма, но не экземпляр базовой модели.')\n",
    "        self.__alg_count = alg_count if alg_count > 1 else 1\n",
    "        self.__s_size = sample_size\n",
    "        self.__s_features = features_in_sample\n",
    "        self.__OOB = OOB\n",
    "        self.__kw = kwargs\n",
    "    \n",
    "    def _get_subsample(self, features_count, features_sample):\n",
    "        subsample = np.random.choice(np.arange(features_count), replace=False, size=features_sample)\n",
    "        return subsample\n",
    "        \n",
    "    def _get_bootstrap(self, data_size, samle_size):\n",
    "        bootstrap = np.random.choice(np.arange(data_size), replace=True, size=samle_size)\n",
    "        return bootstrap\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучает модель.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X, y: array like\n",
    "            Значения признаков и целевой переменной\n",
    "        '''\n",
    "        self.__models = []\n",
    "        self.__OOB_predicts = np.empty_like(y).astype('float')\n",
    "        self.__OOB_predicts[:] = np.nan\n",
    "        y_ind = np.arange(y.shape[0])\n",
    "        s_features = self.__s_features\n",
    "        s_size = self.__s_size\n",
    "        if s_features is None:\n",
    "            s_features = int(X.shape[1]**0.5)\n",
    "        if s_size is None:\n",
    "            s_size = X.shape[0]\n",
    "        elif s_size < 1:\n",
    "            s_size = int(X.shape[0] * s_size)\n",
    "            \n",
    "        for i in range(self.__alg_count):\n",
    "            b_labels = self._get_subsample(X.shape[1], s_features)\n",
    "            b_rows = self._get_bootstrap(X.shape[0], s_size)\n",
    "            b_X = X[b_rows][:, b_labels].copy()\n",
    "            b_y = y[b_rows].copy()\n",
    "            model = self.__algorithm\n",
    "            self.__models.append(model(**self.__kw))\n",
    "            self.__models[i].fit(b_X, b_y)\n",
    "            if self.__OOB:\n",
    "                # TODO: оптимизировать, чтобы предсказания каждого алгоритма производились не по всей X\n",
    "                y_pred = self.__models[i].predict(X)\n",
    "                y_pred = np.where(np.isin(y_ind, b_rows), np.nan, y_pred)\n",
    "                self.__OOB_predicts = np.vstack([self.__OOB_predicts, y_pred.copy()])\n",
    "        if self.__OOB:\n",
    "            self.__OOB_predicts = np.nanmean(self.__OOB_predicts.T, axis=1)\n",
    "        \n",
    "    def predict_OOB(self):\n",
    "        '''\n",
    "        Отдает вероятность принадлежности объекта к классу 1 для не принимающих\n",
    "        в обучении наблюдений в bootstrap выборке.\n",
    "        Для каждого базового алгоритма вычисляется принадлежность к классу в self.fit() и в итоге усредняется. \n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "        return self.__OOB_predicts\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        Отдает вероятность принадлежности объекта к классу 1.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: array like\n",
    "            Значения признаков\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "        predicts = None\n",
    "        for model in self.__models:\n",
    "            model.predict(X)\n",
    "            if predicts is None:\n",
    "                predicts = model.predict(X).reshape(-1, 1)\n",
    "            else:\n",
    "                predicts = np.vstack((predicts.copy(), model.predict(X).reshape(-1, 1)))\n",
    "        return predicts.mean(axis=1)\n",
    "\n",
    "    def predict(self, X, prob=0.5):\n",
    "        '''\n",
    "        Отдает предсказания обученной модели.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: array like\n",
    "            Значения признаков\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "        pred = self.predict_proba(X)\n",
    "        pred = np.where(pred < prob, 0, 1)\n",
    "        return pred\n",
    "    \n",
    "    def fit_predict(self, X, y):\n",
    "        '''\n",
    "        Обучает модель и отдает ее предсказания.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X, y: array like\n",
    "            Значения признаков и целевой переменной\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        X: np.array\n",
    "            Предсказанные значения\n",
    "        '''\n",
    "        self.fit(X, y)\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, labels = datasets.make_classification(n_samples=1000, n_features=5, n_redundant=0, random_state=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BootstrapAggregation(DecisionTree, alg_count=10, features_in_sample=2, sample_size=5, OOB=True, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(data, labels)\n",
    "pred = model.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8       , 0.4       , 0.8       , 0.7       , 0.5       ,\n",
       "       0.7       , 0.9       , 0.5       , 0.7       , 0.7       ,\n",
       "       0.8       , 0.8       , 0.7       , 0.6       , 0.9       ,\n",
       "       0.9       , 0.6       , 0.6       , 0.5       , 0.5       ,\n",
       "       0.5       , 0.6       , 0.4       , 0.6       , 0.44444444,\n",
       "       0.8       , 0.7       , 0.9       , 0.5       , 0.3       ,\n",
       "       0.9       , 0.8       , 0.8       , 0.7       , 0.8       ,\n",
       "       0.5       , 0.6       , 0.6       , 0.6       , 0.7       ,\n",
       "       0.3       , 0.7       , 0.7       , 0.8       , 0.8       ,\n",
       "       0.7       , 0.7       , 0.6       , 0.55555556, 0.8       ,\n",
       "       0.33333333, 0.9       , 0.7       , 0.77777778, 0.7       ,\n",
       "       0.6       , 0.7       , 0.5       , 0.5       , 0.5       ,\n",
       "       0.8       , 0.7       , 0.7       , 0.9       , 0.9       ,\n",
       "       0.6       , 0.8       , 0.9       , 0.7       , 0.7       ,\n",
       "       0.9       , 0.7       , 0.5       , 0.3       , 0.4       ,\n",
       "       0.8       , 0.5       , 0.7       , 0.66666667, 0.3       ,\n",
       "       0.8       , 0.8       , 0.5       , 0.44444444, 0.8       ,\n",
       "       0.8       , 0.6       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.4       , 0.6       , 0.7       , 0.8       , 0.6       ,\n",
       "       0.8       , 0.3       , 0.4       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.7       , 0.6       , 0.4       , 0.5       ,\n",
       "       0.7       , 0.8       , 0.6       , 0.8       , 0.6       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.6       , 0.7       ,\n",
       "       0.7       , 0.9       , 0.7       , 0.7       , 0.7       ,\n",
       "       0.7       , 0.6       , 0.8       , 0.7       , 0.7       ,\n",
       "       0.6       , 0.7       , 0.88888889, 0.7       , 0.8       ,\n",
       "       0.7       , 0.8       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.8       , 0.5       , 0.7       , 0.6       , 0.6       ,\n",
       "       0.6       , 0.8       , 0.6       , 0.6       , 0.9       ,\n",
       "       0.8       , 0.7       , 0.55555556, 0.6       , 0.6       ,\n",
       "       0.5       , 0.8       , 0.8       , 0.6       , 0.7       ,\n",
       "       0.4       , 0.6       , 0.6       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.6       , 0.5       , 0.6       , 0.5       ,\n",
       "       0.7       , 0.6       , 0.6       , 0.7       , 0.9       ,\n",
       "       0.8       , 0.55555556, 0.7       , 0.6       , 0.7       ,\n",
       "       0.5       , 0.7       , 0.6       , 0.8       , 0.8       ,\n",
       "       0.8       , 0.7       , 0.6       , 0.6       , 0.9       ,\n",
       "       0.6       , 0.8       , 0.4       , 0.5       , 0.9       ,\n",
       "       0.55555556, 0.7       , 0.5       , 0.6       , 0.77777778,\n",
       "       0.8       , 0.4       , 0.8       , 0.6       , 0.6       ,\n",
       "       0.6       , 0.6       , 0.4       , 0.7       , 0.6       ,\n",
       "       0.7       , 0.7       , 0.8       , 0.6       , 0.5       ,\n",
       "       0.8       , 0.8       , 0.8       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.6       , 0.5       , 0.8       , 0.8       ,\n",
       "       0.8       , 0.7       , 0.6       , 0.6       , 0.7       ,\n",
       "       0.5       , 0.8       , 0.6       , 0.9       , 0.5       ,\n",
       "       0.6       , 0.7       , 0.5       , 0.6       , 0.9       ,\n",
       "       0.5       , 0.6       , 0.6       , 0.8       , 0.3       ,\n",
       "       0.5       , 0.3       , 0.7       , 0.5       , 0.3       ,\n",
       "       0.9       , 0.9       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.7       , 0.8       , 0.5       , 0.6       , 0.6       ,\n",
       "       0.7       , 0.4       , 0.8       , 0.9       , 0.7       ,\n",
       "       0.9       , 0.5       , 0.44444444, 0.7       , 0.8       ,\n",
       "       0.8       , 0.9       , 0.77777778, 0.3       , 0.6       ,\n",
       "       0.5       , 0.8       , 0.4       , 0.7       , 0.7       ,\n",
       "       0.7       , 0.8       , 0.7       , 0.8       , 0.4       ,\n",
       "       0.8       , 0.8       , 0.8       , 0.5       , 0.7       ,\n",
       "       0.6       , 0.4       , 0.8       , 0.4       , 0.6       ,\n",
       "       0.88888889, 0.5       , 0.8       , 0.5       , 0.7       ,\n",
       "       0.8       , 0.5       , 0.8       , 0.3       , 0.7       ,\n",
       "       0.7       , 0.8       , 0.6       , 0.7       , 0.8       ,\n",
       "       0.7       , 0.7       , 0.4       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.5       , 0.8       , 0.3       ,\n",
       "       0.3       , 0.7       , 0.5       , 0.8       , 0.6       ,\n",
       "       0.7       , 0.5       , 0.7       , 0.4       , 0.7       ,\n",
       "       0.7       , 0.8       , 0.4       , 0.8       , 0.5       ,\n",
       "       0.8       , 0.6       , 0.8       , 0.8       , 0.4       ,\n",
       "       0.5       , 0.4       , 0.6       , 0.8       , 0.44444444,\n",
       "       0.8       , 0.8       , 0.8       , 0.6       , 0.8       ,\n",
       "       0.66666667, 0.8       , 0.8       , 0.7       , 0.6       ,\n",
       "       0.9       , 0.77777778, 0.7       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.7       , 0.9       , 0.7       , 0.8       ,\n",
       "       0.5       , 0.8       , 0.4       , 0.7       , 0.7       ,\n",
       "       0.9       , 0.6       , 0.6       , 0.8       , 0.5       ,\n",
       "       0.6       , 0.9       , 0.6       , 0.6       , 0.66666667,\n",
       "       0.8       , 0.7       , 0.7       , 0.8       , 0.8       ,\n",
       "       0.6       , 0.7       , 0.8       , 0.7       , 0.9       ,\n",
       "       0.7       , 0.6       , 0.7       , 0.6       , 0.77777778,\n",
       "       0.9       , 0.7       , 0.7       , 0.5       , 0.5       ,\n",
       "       0.5       , 0.8       , 0.4       , 0.5       , 0.6       ,\n",
       "       0.75      , 0.8       , 0.9       , 0.7       , 0.7       ,\n",
       "       0.8       , 0.6       , 0.9       , 0.3       , 0.8       ,\n",
       "       0.6       , 0.8       , 0.6       , 0.8       , 0.6       ,\n",
       "       0.6       , 0.4       , 0.6       , 0.9       , 0.6       ,\n",
       "       0.7       , 0.7       , 0.8       , 0.8       , 0.8       ,\n",
       "       0.4       , 0.9       , 0.5       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.3       , 0.8       ,\n",
       "       0.4       , 0.8       , 0.6       , 0.4       , 0.9       ,\n",
       "       0.3       , 0.8       , 0.6       , 0.5       , 0.7       ,\n",
       "       0.55555556, 0.6       , 0.5       , 0.4       , 0.5       ,\n",
       "       0.7       , 0.7       , 0.4       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.7       , 0.8       , 0.6       ,\n",
       "       0.9       , 0.9       , 0.6       , 0.7       , 0.5       ,\n",
       "       0.8       , 0.5       , 0.7       , 0.6       , 1.        ,\n",
       "       0.7       , 0.6       , 0.4       , 0.4       , 0.8       ,\n",
       "       0.6       , 0.7       , 0.7       , 0.3       , 0.6       ,\n",
       "       0.8       , 0.4       , 0.6       , 0.5       , 0.6       ,\n",
       "       0.8       , 0.9       , 0.7       , 0.7       , 0.77777778,\n",
       "       0.6       , 0.7       , 0.6       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.6       , 0.8       , 0.7       , 0.55555556,\n",
       "       0.6       , 0.8       , 0.6       , 0.5       , 0.6       ,\n",
       "       0.6       , 0.9       , 0.5       , 0.8       , 0.5       ,\n",
       "       0.7       , 0.6       , 0.5       , 0.6       , 0.6       ,\n",
       "       0.8       , 0.55555556, 0.7       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.55555556, 0.8       , 0.7       ,\n",
       "       0.9       , 0.7       , 0.9       , 0.4       , 0.9       ,\n",
       "       0.6       , 0.8       , 0.55555556, 0.7       , 0.9       ,\n",
       "       0.5       , 0.6       , 0.6       , 0.9       , 0.7       ,\n",
       "       0.6       , 0.9       , 0.8       , 0.6       , 0.7       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.8       , 0.8       ,\n",
       "       0.6       , 0.8       , 0.7       , 0.6       , 0.4       ,\n",
       "       0.9       , 0.7       , 0.7       , 0.8       , 0.7       ,\n",
       "       0.6       , 0.8       , 0.5       , 0.33333333, 0.8       ,\n",
       "       0.7       , 0.7       , 0.5       , 0.8       , 0.8       ,\n",
       "       0.8       , 0.5       , 0.7       , 0.9       , 0.5       ,\n",
       "       0.7       , 0.6       , 0.6       , 0.77777778, 0.6       ,\n",
       "       0.7       , 0.7       , 0.6       , 0.4       , 0.7       ,\n",
       "       0.6       , 0.4       , 0.8       , 0.8       , 0.9       ,\n",
       "       0.9       , 0.3       , 0.8       , 0.7       , 0.8       ,\n",
       "       0.6       , 0.5       , 0.6       , 0.8       , 0.8       ,\n",
       "       0.6       , 0.8       , 0.6       , 0.6       , 0.8       ,\n",
       "       0.6       , 0.7       , 0.5       , 0.8       , 0.5       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.6       , 0.7       ,\n",
       "       0.6       , 0.6       , 0.9       , 0.8       , 0.8       ,\n",
       "       0.7       , 0.8       , 0.6       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.6       , 0.6       , 0.8       , 0.4       ,\n",
       "       0.8       , 0.7       , 0.7       , 0.5       , 0.7       ,\n",
       "       0.8       , 0.7       , 0.5       , 0.5       , 0.77777778,\n",
       "       0.5       , 0.7       , 0.6       , 0.8       , 0.9       ,\n",
       "       0.6       , 0.5       , 0.7       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.5       , 0.6       , 0.8       , 0.6       ,\n",
       "       0.8       , 0.5       , 0.6       , 0.8       , 0.9       ,\n",
       "       0.9       , 0.5       , 0.55555556, 0.8       , 0.7       ,\n",
       "       0.5       , 0.6       , 0.8       , 0.4       , 0.6       ,\n",
       "       0.5       , 0.7       , 0.6       , 0.6       , 0.7       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.5       , 0.6       ,\n",
       "       0.8       , 0.6       , 0.6       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.3       , 0.6       ,\n",
       "       0.6       , 0.6       , 0.7       , 0.6       , 0.9       ,\n",
       "       0.7       , 0.5       , 0.6       , 0.7       , 0.7       ,\n",
       "       0.6       , 0.6       , 0.9       , 0.8       , 0.44444444,\n",
       "       0.8       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "       0.8       , 0.8       , 0.4       , 0.6       , 0.8       ,\n",
       "       0.7       , 0.5       , 0.8       , 0.7       , 0.9       ,\n",
       "       0.8       , 0.6       , 0.6       , 0.5       , 0.7       ,\n",
       "       0.6       , 0.6       , 0.5       , 0.6       , 0.55555556,\n",
       "       0.8       , 0.7       , 0.75      , 0.4       , 0.7       ,\n",
       "       0.5       , 0.7       , 0.8       , 0.8       , 0.5       ,\n",
       "       0.7       , 0.8       , 0.6       , 0.66666667, 0.7       ,\n",
       "       0.7       , 0.7       , 0.6       , 0.5       , 0.7       ,\n",
       "       0.6       , 0.5       , 0.5       , 0.5       , 0.4       ,\n",
       "       0.8       , 0.7       , 0.7       , 0.7       , 0.8       ,\n",
       "       0.8       , 0.6       , 0.6       , 0.5       , 0.7       ,\n",
       "       0.8       , 0.8       , 0.7       , 0.9       , 0.4       ,\n",
       "       0.8       , 0.6       , 0.6       , 0.8       , 0.8       ,\n",
       "       0.6       , 0.6       , 0.6       , 0.5       , 0.7       ,\n",
       "       0.9       , 0.8       , 0.5       , 0.6       , 0.7       ,\n",
       "       0.9       , 0.8       , 0.6       , 0.7       , 0.9       ,\n",
       "       0.4       , 0.8       , 0.88888889, 0.8       , 0.8       ,\n",
       "       0.6       , 0.6       , 0.8       , 0.6       , 0.6       ,\n",
       "       0.6       , 0.6       , 0.6       , 0.9       , 0.6       ,\n",
       "       0.7       , 0.6       , 0.8       , 0.5       , 0.5       ,\n",
       "       0.7       , 0.8       , 0.5       , 0.7       , 0.5       ,\n",
       "       0.6       , 0.3       , 0.7       , 0.7       , 0.6       ,\n",
       "       0.5       , 0.3       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.8       , 0.5       , 0.8       , 0.6       , 0.8       ,\n",
       "       0.7       , 0.8       , 0.5       , 0.5       , 0.7       ,\n",
       "       0.7       , 0.8       , 0.8       , 0.7       , 0.5       ,\n",
       "       0.7       , 0.8       , 0.5       , 0.66666667, 0.8       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.3       , 0.6       ,\n",
       "       0.6       , 0.6       , 0.8       , 0.5       , 0.7       ,\n",
       "       0.9       , 0.7       , 0.6       , 0.88888889, 0.8       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.7       , 0.6       ,\n",
       "       0.55555556, 0.7       , 0.6       , 0.6       , 0.3       ,\n",
       "       0.7       , 0.7       , 0.7       , 0.6       , 0.7       ,\n",
       "       0.6       , 0.5       , 0.7       , 0.3       , 0.5       ,\n",
       "       0.9       , 0.8       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.3       , 0.8       , 0.4       , 0.6       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.8       , 0.5       ,\n",
       "       0.5       , 0.7       , 0.5       , 0.6       , 0.8       ,\n",
       "       0.5       , 0.5       , 0.5       , 0.8       , 0.6       ,\n",
       "       0.6       , 0.4       , 0.8       , 0.6       , 0.4       ,\n",
       "       0.3       , 0.6       , 0.8       , 0.6       , 0.3       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.5       , 0.77777778,\n",
       "       0.7       , 0.5       , 0.8       , 0.88888889, 0.9       ,\n",
       "       0.4       , 0.9       , 0.5       , 0.5       , 0.5       ,\n",
       "       0.7       , 0.6       , 0.8       , 0.77777778, 0.7       ,\n",
       "       0.5       , 0.77777778, 0.6       , 0.66666667, 0.7       ,\n",
       "       0.44444444, 0.5       , 0.6       , 0.6       , 0.6       ,\n",
       "       0.8       , 0.5       , 0.8       , 0.4       , 0.55555556,\n",
       "       0.8       , 0.8       , 0.6       , 0.8       , 0.8       ,\n",
       "       0.8       , 0.8       , 0.6       , 0.8       , 0.6       ,\n",
       "       0.6       , 0.8       , 0.8       , 0.7       , 0.9       ,\n",
       "       0.6       , 0.6       , 0.44444444, 0.8       , 0.4       ,\n",
       "       0.9       , 0.8       , 0.8       , 0.7       , 0.6       ,\n",
       "       0.7       , 0.7       , 0.6       , 0.8       , 0.5       ,\n",
       "       0.8       , 0.7       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.6       , 0.7       , 0.8       , 0.8       , 0.6       ,\n",
       "       0.6       , 0.5       , 0.7       , 0.6       , 0.6       ,\n",
       "       0.9       , 0.7       , 0.6       , 0.8       , 0.6       ])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_OOB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
